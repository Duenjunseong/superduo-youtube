"""
YouTube íŠ¸ë Œë”© í˜ì´ì§€ì—ì„œ ì‡¼ì¸  ì •ë³´ë¥¼ ìŠ¤í¬ë˜í•‘í•˜ëŠ” ê´€ë¦¬ ëª…ë ¹ì–´
"""

from django.core.management.base import BaseCommand, CommandError
from django.utils import timezone
from youtube_trending.services import YouTubeTrendingScraper, TrendingDataService
import logging

logger = logging.getLogger(__name__)


class Command(BaseCommand):
    help = 'Seleniumì„ ì‚¬ìš©í•˜ì—¬ YouTube íŠ¸ë Œë”© í˜ì´ì§€ì—ì„œ ì‡¼ì¸  ì •ë³´ë¥¼ ìŠ¤í¬ë˜í•‘í•©ë‹ˆë‹¤'

    def add_arguments(self, parser):
        parser.add_argument(
            '--scrape-only',
            action='store_true',
            help='ìŠ¤í¬ë˜í•‘ë§Œ ìˆ˜í–‰ (API ìˆ˜ì§‘ ì œì™¸)',
        )
        parser.add_argument(
            '--api-only',
            action='store_true',
            help='API ìˆ˜ì§‘ë§Œ ìˆ˜í–‰ (ìŠ¤í¬ë˜í•‘ ì œì™¸)',
        )
        parser.add_argument(
            '--test-mode',
            action='store_true',
            help='í…ŒìŠ¤íŠ¸ ëª¨ë“œ (ì‹¤ì œ ì €ì¥í•˜ì§€ ì•ŠìŒ)',
        )
        parser.add_argument(
            '--save-html',
            action='store_true',
            help='ë Œë”ë§ëœ HTMLì„ íŒŒì¼ë¡œ ì €ì¥ (ë””ë²„ê¹…ìš©)',
        )
        parser.add_argument(
            '--debug',
            action='store_true',
            help='ë””ë²„ê·¸ ëª¨ë“œ (ìƒì„¸í•œ ë¡œê·¸ ì¶œë ¥)',
        )
        parser.add_argument(
            '--no-enhancement',
            action='store_true',
            help='yt-dlp ë©”íƒ€ë°ì´í„° ë³´ê°• ë¹„í™œì„±í™”',
        )
        parser.add_argument(
            '--limit',
            type=int,
            default=50,
            help='ìˆ˜ì§‘í•  ìµœëŒ€ ì‡¼ì¸  ìˆ˜ (ê¸°ë³¸ê°’: 50)',
        )
        parser.add_argument(
            '--retries',
            type=int,
            default=3,
            help='ì¬ì‹œë„ íšŸìˆ˜ (ê¸°ë³¸ê°’: 3)',
        )
        parser.add_argument(
            '--workers',
            type=int,
            default=6,
            help='ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜ (ê¸°ë³¸ê°’: 6)',
        )
        parser.add_argument(
            '--no-parallel',
            action='store_true',
            help='ë³‘ë ¬ ì²˜ë¦¬ ë¹„í™œì„±í™” (ìˆœì°¨ ì²˜ë¦¬)',
        )

    def handle(self, *args, **options):
        start_time = timezone.now()
        
        # ì˜µì…˜ ì €ì¥
        self.options = options
        
        # ë””ë²„ê·¸ ëª¨ë“œ ì„¤ì •
        if options['debug']:
            logging.getLogger('youtube_trending.services').setLevel(logging.DEBUG)
        
        self.stdout.write(
            self.style.HTTP_INFO('=' * 60)
        )
        self.stdout.write(
            self.style.HTTP_INFO('ğŸ¤– Selenium YouTube íŠ¸ë Œë”© ì‡¼ì¸  ìŠ¤í¬ë˜í•‘ ì‹œì‘')
        )
        self.stdout.write(
            self.style.HTTP_INFO(f'ì‹œì‘ ì‹œê°„: {start_time.strftime("%Y-%m-%d %H:%M:%S")}')
        )
        if options['test_mode']:
            self.stdout.write(
                self.style.WARNING('ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ í™œì„±í™” - ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤')
            )
        if options['save_html']:
            self.stdout.write(
                self.style.HTTP_INFO('ğŸ’¾ HTML ì €ì¥ ëª¨ë“œ í™œì„±í™”')
            )
        self.stdout.write(
            self.style.HTTP_INFO('=' * 60)
        )

        try:
            if options['scrape_only']:
                # Selenium ìŠ¤í¬ë˜í•‘ë§Œ ìˆ˜í–‰
                result = self.run_selenium_scraping_only(options['test_mode'], options['save_html'])
            elif options['api_only']:
                # APIë§Œ ìˆ˜í–‰ (ê¸°ì¡´ ê¸°ëŠ¥)
                result = self.run_api_only()
            else:
                # í†µí•© ìˆ˜ì§‘ (API + Selenium ìŠ¤í¬ë˜í•‘)
                result = self.run_integrated_collection(options['test_mode'])
            
            self.display_results(result, start_time)
            
        except Exception as e:
            self.stdout.write(
                self.style.ERROR(f'âŒ ìŠ¤í¬ë˜í•‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}')
            )
            logger.error(f'ìŠ¤í¬ë˜í•‘ ëª…ë ¹ì–´ ì‹¤í–‰ ì‹¤íŒ¨: {e}', exc_info=True)
            raise CommandError(f'ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {str(e)}')

    def run_selenium_scraping_only(self, test_mode=False, save_html=False):
        """í–¥ìƒëœ Seleniumì„ ì‚¬ìš©í•œ ìŠ¤í¬ë˜í•‘ë§Œ ìˆ˜í–‰"""
        enhance_metadata = not self.options.get('no_enhancement', False)
        limit = self.options.get('limit', 50)
        retries = self.options.get('retries', 3)
        workers = self.options.get('workers', 6)
        use_parallel = not self.options.get('no_parallel', False)
        
        # ì„¤ì • ì •ë³´ ì¶œë ¥
        settings_info = []
        settings_info.append(f"ë©”íƒ€ë°ì´í„° ë³´ê°•: {'âœ… í™œì„±í™”' if enhance_metadata else 'âŒ ë¹„í™œì„±í™”'}")
        settings_info.append(f"ìµœëŒ€ ì‡¼ì¸  ìˆ˜: {limit}ê°œ")
        settings_info.append(f"ì¬ì‹œë„ íšŸìˆ˜: {retries}íšŒ")
        if enhance_metadata:
            settings_info.append(f"ë³‘ë ¬ ì²˜ë¦¬: {'âœ… í™œì„±í™”' if use_parallel else 'âŒ ë¹„í™œì„±í™”'}")
            if use_parallel:
                settings_info.append(f"ì›Œì»¤ ìˆ˜: {workers}ê°œ")
        
        self.stdout.write(f'ğŸ¤– í–¥ìƒëœ Selenium ì‡¼ì¸  ìŠ¤í¬ë˜í•‘ ì‹œì‘...')
        self.stdout.write(f'âš™ï¸  ì„¤ì •: {" | ".join(settings_info)}')
        self.stdout.write(f'ğŸ“Š í˜„ì¬ í˜ì´ì§€ì—ì„œ ì‡¼ì¸  ìˆ˜ì§‘ (ì¡°íšŒìˆ˜ ê¸°ì¤€ ì •ë ¬, ìµœëŒ€ {limit}ê°œ)')
        
        # í–¥ìƒëœ ìŠ¤í¬ë˜í¼ ìƒì„±
        scraper = YouTubeTrendingScraper(
            use_metadata_enhancement=enhance_metadata,
            max_retries=retries
        )
        
        # ë©”íƒ€ë°ì´í„° ì¶”ì¶œê¸° ì„¤ì • ì¡°ì •
        if enhance_metadata:
            scraper.metadata_extractor.max_workers = workers
        
        # 1. Chrome WebDriver ì¤€ë¹„ ìƒíƒœ í™•ì¸
        self.stdout.write('ğŸ”§ Chrome WebDriver ì„¤ì • í™•ì¸ ì¤‘...')
        
        # 2. YouTube íŠ¸ë Œë”© í˜ì´ì§€ ì ‘ê·¼ ë° ì‡¼ì¸  ìˆ˜ì§‘
        self.stdout.write('ğŸŒ í˜„ì¬ í˜ì´ì§€ì—ì„œ ì‡¼ì¸  ìˆ˜ì§‘ ì‹œì‘...')
        try:
            shorts_data = scraper.scrape_trending_shorts(
                enhance_metadata=enhance_metadata, 
                max_shorts=limit
            )
            self.stdout.write(f'âœ… ìˆ˜ì§‘ ì™„ë£Œ: {len(shorts_data)}ê°œ ì‡¼ì¸  (ì¡°íšŒìˆ˜ ê¸°ì¤€ ì •ë ¬ë¨)')
            
        except Exception as e:
            self.stdout.write(self.style.ERROR(f'âŒ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}'))
            raise
        
        # 3. ë°ì´í„° ê²€ì¦
        self.stdout.write('ğŸ” ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì¤‘...')
        validated_data = scraper._validate_shorts_data(shorts_data)
        if len(validated_data) != len(shorts_data):
            self.stdout.write(f'ğŸ”„ ê²€ì¦ ì™„ë£Œ: {len(shorts_data)}ê°œ â†’ {len(validated_data)}ê°œ')
        
        # 4. ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
        if validated_data:
            self.stdout.write('\nğŸ“Š ìˆ˜ì§‘ëœ ì‡¼ì¸  ë¯¸ë¦¬ë³´ê¸°:')
            for i, shorts in enumerate(validated_data[:3], 1):
                title = shorts.get('title', '')[:50]
                view_count = shorts.get('view_count', 0)
                channel = shorts.get('channel_title', '')[:20]
                enhancement_status = "ğŸ”¥ í–¥ìƒë¨" if enhance_metadata and shorts.get('like_count', 0) > 0 else "ğŸ“‹ ê¸°ë³¸"
                
                self.stdout.write(f'  {i}. {title}... | ì¡°íšŒìˆ˜: {view_count:,} | ì±„ë„: {channel} | {enhancement_status}')
            
            if len(validated_data) > 3:
                self.stdout.write(f'  ... ì™¸ {len(validated_data) - 3}ê°œ ë”')
        
        # 5. ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ (í…ŒìŠ¤íŠ¸ ëª¨ë“œê°€ ì•„ë‹Œ ê²½ìš°)
        if not test_mode and validated_data:
            self.stdout.write('\nğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘...')
            try:
                created, updated = scraper.save_scraped_shorts_to_db(validated_data)
                self.stdout.write(f'âœ… ì €ì¥ ì™„ë£Œ: ìƒˆë¡œ ìƒì„± {created}ê°œ, ì—…ë°ì´íŠ¸ {updated}ê°œ')
                
                return {
                    'total_scraped': len(validated_data),
                    'created': created,
                    'updated': updated,
                    'total_saved': created + updated,
                    'enhancement_used': enhance_metadata,
                    'parallel_used': use_parallel and enhance_metadata,
                }
                
            except Exception as e:
                self.stdout.write(self.style.ERROR(f'âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}'))
                raise
        
        elif test_mode:
            self.stdout.write('\nğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ì§€ ì•ŠìŒ')
            return {
                'total_scraped': len(validated_data),
                'created': 0,
                'updated': 0,
                'total_saved': 0,
                'enhancement_used': enhance_metadata,
                'parallel_used': use_parallel and enhance_metadata,
                'test_mode': True,
            }
        
        else:
            self.stdout.write('â„¹ï¸  ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ì–´ ì €ì¥í•˜ì§€ ì•ŠìŒ')
            return {
                'total_scraped': 0,
                'created': 0,
                'updated': 0,
                'total_saved': 0,
                'enhancement_used': enhance_metadata,
                'parallel_used': use_parallel and enhance_metadata,
            }

    def run_api_only(self):
        """APIë§Œ ìˆ˜í–‰"""
        self.stdout.write('ğŸ”‘ YouTube APIë¥¼ í†µí•œ íŠ¸ë Œë”© ë™ì˜ìƒ ìˆ˜ì§‘ ì‹œì‘...')
        
        # ê¸°ì¡´ API ì„œë¹„ìŠ¤ ì‚¬ìš©
        from youtube_trending.services import YouTubeAPIService
        api_service = YouTubeAPIService()
        
        try:
            videos = api_service.get_trending_videos()
            self.stdout.write(
                self.style.SUCCESS(f'âœ… APIì—ì„œ {len(videos)}ê°œ ë™ì˜ìƒ ìˆ˜ì§‘ ì™„ë£Œ')
            )
            
            # ì—¬ê¸°ì„œ ì‹¤ì œ ì €ì¥ ë¡œì§ì„ êµ¬í˜„í•´ì•¼ í•¨ (ê¸°ì¡´ collect_trending.py ì°¸ê³ )
            return {
                'api_collection': {
                    'success': True,
                    'count': len(videos),
                    'error': None
                },
                'total_collected': len(videos)
            }
            
        except Exception as e:
            self.stdout.write(
                self.style.ERROR(f'âŒ API ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}')
            )
            raise

    def run_integrated_collection(self, test_mode=False):
        """í†µí•© ìˆ˜ì§‘ (API + Selenium ìŠ¤í¬ë˜í•‘)"""
        self.stdout.write('ğŸš€ í†µí•© íŠ¸ë Œë”© ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (API + Selenium)...')
        
        if test_mode:
            # í…ŒìŠ¤íŠ¸ ëª¨ë“œì—ì„œëŠ” Selenium ìŠ¤í¬ë˜í•‘ë§Œ ìˆ˜í–‰
            return self.run_selenium_scraping_only(test_mode=True)
        
        integrated_service = TrendingDataService()
        
        try:
            results = integrated_service.collect_all_trending_data()
            return results
            
        except Exception as e:
            self.stdout.write(
                self.style.ERROR(f'âŒ í†µí•© ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}')
            )
            raise

    def display_results(self, results, start_time):
        """ê²°ê³¼ í‘œì‹œ"""
        end_time = timezone.now()
        duration = end_time - start_time
        
        self.stdout.write('\n' + '=' * 60)
        self.stdout.write(
            self.style.SUCCESS('ğŸ‰ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ!')
        )
        self.stdout.write(f'â±ï¸  ì†Œìš” ì‹œê°„: {duration.total_seconds():.1f}ì´ˆ')
        
        # API ê²°ê³¼
        if 'api_collection' in results:
            api_result = results['api_collection']
            if api_result['success']:
                self.stdout.write(
                    self.style.SUCCESS(f'ğŸ“Š API ìˆ˜ì§‘: {api_result["count"]}ê°œ')
                )
                if 'created' in api_result and 'updated' in api_result:
                    self.stdout.write(f'   - ìƒˆë¡œ ìƒì„±: {api_result["created"]}ê°œ')
                    self.stdout.write(f'   - ì—…ë°ì´íŠ¸: {api_result["updated"]}ê°œ')
            else:
                self.stdout.write(
                    self.style.ERROR(f'âŒ API ìˆ˜ì§‘ ì‹¤íŒ¨: {api_result.get("error", "Unknown error")}')
                )
        
        # ìŠ¤í¬ë˜í•‘ ê²°ê³¼
        if 'scraping_collection' in results:
            scraping_result = results['scraping_collection']
            method = scraping_result.get('method', 'unknown')
            method_icon = 'ğŸ¤–' if method == 'selenium' else 'ğŸ“±'
            
            if scraping_result['success']:
                self.stdout.write(
                    self.style.SUCCESS(f'{method_icon} ìŠ¤í¬ë˜í•‘ ({method}): {scraping_result["count"]}ê°œ')
                )
                if 'created' in scraping_result and 'updated' in scraping_result:
                    self.stdout.write(f'   - ìƒˆë¡œ ìƒì„±: {scraping_result["created"]}ê°œ')
                    self.stdout.write(f'   - ì—…ë°ì´íŠ¸: {scraping_result["updated"]}ê°œ')
            else:
                self.stdout.write(
                    self.style.ERROR(f'âŒ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {scraping_result.get("error", "Unknown error")}')
                )
        
        # ì „ì²´ ê²°ê³¼
        total = results.get('total_collected', 0)
        if total > 0:
            self.stdout.write(
                self.style.HTTP_INFO(f'ğŸ“ˆ ì´ ìˆ˜ì§‘ëœ í•­ëª©: {total}ê°œ')
            )
        else:
            self.stdout.write(
                self.style.WARNING(f'âš ï¸  ìˆ˜ì§‘ëœ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.')
            )
        
        self.stdout.write('=' * 60) 